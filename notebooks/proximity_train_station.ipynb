{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: /home/Daniel Bi/project two/data/landing/PTV_train_station\n",
      "Extracted files in PTV folder: ['ptv_metro_train_station_column_names.txt', 'PTV_METRO_TRAIN_STATION.prj', 'PTV_METRO_TRAIN_STATION.dbf', 'PTV_METRO_TRAIN_STATION.shp', 'PTV_METRO_TRAIN_STATION.shx', 'PTV_METRO_TRAIN_STATION.cpg']\n",
      "Shapefile found: /home/Daniel Bi/project two/data/landing/PTV_train_station/PTV/PTV_METRO_TRAIN_STATION.shp\n",
      "Train station shapefile loaded successfully.\n",
      "  STOP_ID   LATITUDE                                          STOP_NAME  \\\n",
      "0   19970 -37.781193             Royal Park Railway Station (Parkville)   \n",
      "1   19971 -37.788140  Flemington Bridge Railway Station (North Melbo...   \n",
      "2   19972 -37.794267         Macaulay Railway Station (North Melbourne)   \n",
      "3   19973 -37.807419   North Melbourne Railway Station (West Melbourne)   \n",
      "4   19974 -37.788657        Clifton Hill Railway Station (Clifton Hill)   \n",
      "\n",
      "    LONGITUDE TICKETZONE                                          ROUTEUSSP  \\\n",
      "0  144.952301          1                                            Upfield   \n",
      "1  144.939323          1                                            Upfield   \n",
      "2  144.936166          1                                            Upfield   \n",
      "3  144.942570          1  Flemington,Sunbury,Upfield,Werribee,Williamsto...   \n",
      "4  144.995417          1                                 Mernda,Hurstbridge   \n",
      "\n",
      "                          geometry  \n",
      "0    POINT (2495798.33 2413308.75)  \n",
      "1  POINT (2494655.621 2412537.079)  \n",
      "2  POINT (2494377.992 2411856.882)  \n",
      "3   POINT (2494942.89 2410397.549)  \n",
      "4  POINT (2499596.331 2412481.387)  \n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "# File path to the ZIP file containing the train station shapefile\n",
    "zip_file_path = '/home/Daniel Bi/project two/data/landing/PTV.zip'\n",
    "extract_dir = '/home/Daniel Bi/project two/data/landing/PTV_train_station'\n",
    "\n",
    "# Step 1: Extract the ZIP file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "    print(f\"Files extracted to: {extract_dir}\")\n",
    "\n",
    "# Step 2: List the files in the 'PTV' subdirectory to check for the correct shapefile name\n",
    "ptv_subdir = os.path.join(extract_dir, 'PTV')\n",
    "extracted_files = os.listdir(ptv_subdir)\n",
    "print(\"Extracted files in PTV folder:\", extracted_files)\n",
    "\n",
    "# Step 3: Find the shapefile (.shp) in the 'PTV' folder\n",
    "shapefile_name = [file for file in extracted_files if file.endswith('.shp')]\n",
    "if shapefile_name:\n",
    "    shapefile_path = os.path.join(ptv_subdir, shapefile_name[0])\n",
    "    print(f\"Shapefile found: {shapefile_path}\")\n",
    "\n",
    "    # Step 4: Load the train station shapefile\n",
    "    try:\n",
    "        train_station_gdf = gpd.read_file(shapefile_path)\n",
    "        print(\"Train station shapefile loaded successfully.\")\n",
    "        print(train_station_gdf.head())\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading train station shapefile: {e}\")\n",
    "else:\n",
    "    print(\"No shapefile found in the 'PTV' folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geocode to convert addresses to latitude and longtitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "# File path for the rental data CSV\n",
    "rental_data_path = '/home/Daniel Bi/project two/data/landing/rental_scrape.csv'\n",
    "\n",
    "# Step 1: Load the rental data CSV\n",
    "rental_df = pd.read_csv(rental_data_path)\n",
    "\n",
    "# Step 2: Initialize Nominatim geocoder with retry logic\n",
    "geolocator = Nominatim(user_agent=\"rental_geocoder\", timeout=10)\n",
    "\n",
    "# Create a session with retry settings to handle temporary errors\n",
    "session = requests.Session()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])\n",
    "adapter = HTTPAdapter(max_retries=retries)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "\n",
    "# Step 3: Function to geocode addresses with retries\n",
    "def geocode_address(address):\n",
    "    try:\n",
    "        location = geolocator.geocode(address, timeout=10)\n",
    "        if location:\n",
    "            return (location.latitude, location.longitude)\n",
    "        else:\n",
    "            return (None, None)\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {address}: {e}\")\n",
    "        return (None, None)\n",
    "\n",
    "# Step 4: Apply geocoding function to the 'Address' column with retry logic\n",
    "rental_df['coordinates'] = rental_df['Address'].apply(lambda address: geocode_address(address))\n",
    "\n",
    "# Step 5: Split coordinates into 'latitude' and 'longitude' columns\n",
    "rental_df['latitude'] = rental_df['coordinates'].apply(lambda x: x[0])\n",
    "rental_df['longitude'] = rental_df['coordinates'].apply(lambda x: x[1])\n",
    "\n",
    "# Step 6: Save the DataFrame with geocoded coordinates to a new CSV\n",
    "rental_df.to_csv('/home/Daniel Bi/project two/data/landing/rental_with_coordinates.csv', index=False)\n",
    "\n",
    "# Optional: Display the first few rows to verify\n",
    "print(rental_df[['Address', 'latitude', 'longitude']].head())\n",
    "\n",
    "# Add a small delay between requests to avoid being blocked by Nominatim API\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate distance to cloest train station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: /home/Daniel Bi/project two/data/landing/PTV_train_station\n",
      "Shapefile found: /home/Daniel Bi/project two/data/landing/PTV_train_station/PTV/PTV_METRO_TRAIN_STATION.shp\n",
      "Train station shapefile loaded and reprojected successfully.\n",
      "Processed 100 rows, saving progress...\n",
      "Processed 200 rows, saving progress...\n",
      "Processed 300 rows, saving progress...\n",
      "Processed 400 rows, saving progress...\n",
      "Processed 500 rows, saving progress...\n",
      "Processed 600 rows, saving progress...\n",
      "Processed 700 rows, saving progress...\n",
      "Processed 800 rows, saving progress...\n",
      "Processed 900 rows, saving progress...\n",
      "Processed 1000 rows, saving progress...\n",
      "Processed 1100 rows, saving progress...\n",
      "Processed 1200 rows, saving progress...\n",
      "Processed 1300 rows, saving progress...\n",
      "Processed 1400 rows, saving progress...\n",
      "Processed 1500 rows, saving progress...\n",
      "Processed 1600 rows, saving progress...\n",
      "Processed 1700 rows, saving progress...\n",
      "Processed 1800 rows, saving progress...\n",
      "Processed 1900 rows, saving progress...\n",
      "Processed 2000 rows, saving progress...\n",
      "Processed 2100 rows, saving progress...\n",
      "Processed 2200 rows, saving progress...\n",
      "Processed 2300 rows, saving progress...\n",
      "Processed 2400 rows, saving progress...\n",
      "Processed 2500 rows, saving progress...\n",
      "Processed 2600 rows, saving progress...\n",
      "Processed 2700 rows, saving progress...\n",
      "Processed 2800 rows, saving progress...\n",
      "Processed 2900 rows, saving progress...\n",
      "Processed 3000 rows, saving progress...\n",
      "Processed 3100 rows, saving progress...\n",
      "Processed 3200 rows, saving progress...\n",
      "Processed 3300 rows, saving progress...\n",
      "Processed 3400 rows, saving progress...\n",
      "Processed 3500 rows, saving progress...\n",
      "Processed 3600 rows, saving progress...\n",
      "Processed 3700 rows, saving progress...\n",
      "Processed 3800 rows, saving progress...\n",
      "Processed 3900 rows, saving progress...\n",
      "Processed 4000 rows, saving progress...\n",
      "Processed 4100 rows, saving progress...\n",
      "Processed 4200 rows, saving progress...\n",
      "Processed 4300 rows, saving progress...\n",
      "Processed 4400 rows, saving progress...\n",
      "Processed 4500 rows, saving progress...\n",
      "Processed 4600 rows, saving progress...\n",
      "Processed 4700 rows, saving progress...\n",
      "Processed 4800 rows, saving progress...\n",
      "Processed 4900 rows, saving progress...\n",
      "Processed 5000 rows, saving progress...\n",
      "Processed 5100 rows, saving progress...\n",
      "Processed 5200 rows, saving progress...\n",
      "Processed 5300 rows, saving progress...\n",
      "Processed 5400 rows, saving progress...\n",
      "Processed 5500 rows, saving progress...\n",
      "Processed 5600 rows, saving progress...\n",
      "Processed 5700 rows, saving progress...\n",
      "Processed 5800 rows, saving progress...\n",
      "Processed 5900 rows, saving progress...\n",
      "Processed 6000 rows, saving progress...\n",
      "Processed 6100 rows, saving progress...\n",
      "Processed 6200 rows, saving progress...\n",
      "Processed 6300 rows, saving progress...\n",
      "Processed 6400 rows, saving progress...\n",
      "Processed 6500 rows, saving progress...\n",
      "Processed 6600 rows, saving progress...\n",
      "Processed 6700 rows, saving progress...\n",
      "Processed 6800 rows, saving progress...\n",
      "Processed 6900 rows, saving progress...\n",
      "Processed 7000 rows, saving progress...\n",
      "Processed 7100 rows, saving progress...\n",
      "Processed 7200 rows, saving progress...\n",
      "Processed 7300 rows, saving progress...\n",
      "Processed 7400 rows, saving progress...\n",
      "Processed 7500 rows, saving progress...\n",
      "Processed 7600 rows, saving progress...\n",
      "Processed 7700 rows, saving progress...\n",
      "Processed 7800 rows, saving progress...\n",
      "Processed 7900 rows, saving progress...\n",
      "Processed 8000 rows, saving progress...\n",
      "Processed 8100 rows, saving progress...\n",
      "Processed 8200 rows, saving progress...\n",
      "Processed 8300 rows, saving progress...\n",
      "Processed 8400 rows, saving progress...\n",
      "Processed 8500 rows, saving progress...\n",
      "Processed 8600 rows, saving progress...\n",
      "Processed 8700 rows, saving progress...\n",
      "Processed 8800 rows, saving progress...\n",
      "Processed 8900 rows, saving progress...\n",
      "Processed 9000 rows, saving progress...\n",
      "Processed 9100 rows, saving progress...\n",
      "Processed 9200 rows, saving progress...\n",
      "Processed 9300 rows, saving progress...\n",
      "Processed 9400 rows, saving progress...\n",
      "Processed 9500 rows, saving progress...\n",
      "Processed 9600 rows, saving progress...\n",
      "Processed 9700 rows, saving progress...\n",
      "Processed 9800 rows, saving progress...\n",
      "Processed 9900 rows, saving progress...\n",
      "Processed 10000 rows, saving progress...\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import googlemaps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "import geopandas as gpd\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Initialize the Google Maps API client with your API key\n",
    "gmaps = googlemaps.Client(key='AIzaSyDO3Op75ZC9rzjZN-HyFbFveFOzPglOJtc')\n",
    "\n",
    "# File paths\n",
    "rental_data_path = '/home/Daniel Bi/project two/data/landing/rental_with_cbd_distances.csv'\n",
    "zip_file_path = '/home/Daniel Bi/project two/data/landing/PTV.zip'\n",
    "extract_dir = '/home/Daniel Bi/project two/data/landing/PTV_train_station'\n",
    "\n",
    "# Step 1: Extract the ZIP file containing the train station shapefile\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "    print(f\"Files extracted to: {extract_dir}\")\n",
    "\n",
    "# Step 2: Load the shapefile (.shp) from the extracted files\n",
    "ptv_subdir = os.path.join(extract_dir, 'PTV')\n",
    "shapefile_name = [file for file in os.listdir(ptv_subdir) if file.endswith('.shp')]\n",
    "\n",
    "if shapefile_name:\n",
    "    shapefile_path = os.path.join(ptv_subdir, shapefile_name[0])\n",
    "    print(f\"Shapefile found: {shapefile_path}\")\n",
    "\n",
    "    # Step 3: Load the train station shapefile and reproject to WGS84 (lat/lon)\n",
    "    try:\n",
    "        train_station_gdf = gpd.read_file(shapefile_path)\n",
    "        train_station_gdf = train_station_gdf.to_crs(epsg=4326)  # Reproject to WGS84 (EPSG:4326)\n",
    "        print(\"Train station shapefile loaded and reprojected successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading train station shapefile: {e}\")\n",
    "else:\n",
    "    print(\"No shapefile found in the 'PTV' folder.\")\n",
    "\n",
    "# Step 4: Prepare train station data for distance calculation\n",
    "train_station_df = train_station_gdf[['STOP_NAME', 'geometry']].copy()\n",
    "train_station_df['latitude'] = train_station_df['geometry'].y\n",
    "train_station_df['longitude'] = train_station_df['geometry'].x\n",
    "train_station_df_clean = train_station_df[['STOP_NAME', 'latitude', 'longitude']].dropna()\n",
    "\n",
    "# Step 5: Load the rental data CSV (with CBD distances already calculated)\n",
    "rental_df = pd.read_csv(rental_data_path)\n",
    "\n",
    "# Filter out rows where latitude or longitude is NaN for rental data\n",
    "rental_df_clean = rental_df.dropna(subset=['latitude', 'longitude']).copy()\n",
    "\n",
    "# Initialize the new columns for storing distances to the closest train station\n",
    "rental_df_clean['closest_train_station'] = None\n",
    "rental_df_clean['straight_line_distance_km'] = None\n",
    "rental_df_clean['route_distance_to_closest_train_km'] = None\n",
    "\n",
    "# Step 6: Calculate the straight-line (Haversine) distance\n",
    "def calculate_closest_station(property_coords, stations_df):\n",
    "    min_distance = float('inf')\n",
    "    closest_station = None\n",
    "    \n",
    "    for _, station in stations_df.iterrows():\n",
    "        station_coords = (station['latitude'], station['longitude'])\n",
    "        distance = geodesic(property_coords, station_coords).kilometers  # Calculate straight-line distance\n",
    "        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_station = station['STOP_NAME']\n",
    "    \n",
    "    return closest_station, min_distance\n",
    "\n",
    "# Step 7: Calculate the driving route distance using Google Maps API\n",
    "def calculate_route_distance(property_coords, station_coords, gmaps_client):\n",
    "    try:\n",
    "        # Request the driving distance between the property and the closest train station\n",
    "        result = gmaps_client.distance_matrix(origins=[property_coords], destinations=[station_coords], mode=\"driving\")\n",
    "        \n",
    "        # Check if the result is valid\n",
    "        if result['rows'][0]['elements'][0]['status'] == 'OK':\n",
    "            distance = result['rows'][0]['elements'][0]['distance']['value']  # Distance in meters\n",
    "            return distance / 1000  # Convert from meters to kilometers\n",
    "        else:\n",
    "            print(f\"No valid route distance found for {property_coords} to station: {result['rows'][0]['elements'][0]['status']}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating route distance for {property_coords}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 8: Process each property to calculate the closest train station and route distance\n",
    "rental_df_clean['coordinates'] = rental_df_clean.apply(lambda row: (row['latitude'], row['longitude']), axis=1)\n",
    "\n",
    "for idx, row in rental_df_clean.iterrows():\n",
    "    if pd.isnull(row['route_distance_to_closest_train_km']):  # Only process rows with null distances\n",
    "        coords = row['coordinates']\n",
    "        \n",
    "        # Step 8a: Find the closest train station using straight-line distance\n",
    "        closest_station, straight_line_distance = calculate_closest_station(coords, train_station_df_clean)\n",
    "        rental_df_clean.loc[idx, 'closest_train_station'] = closest_station\n",
    "        rental_df_clean.loc[idx, 'straight_line_distance_km'] = straight_line_distance\n",
    "        \n",
    "        # Get the coordinates of the closest station\n",
    "        station_coords = train_station_df_clean[train_station_df_clean['STOP_NAME'] == closest_station][['latitude', 'longitude']].values[0]\n",
    "        \n",
    "        # Step 8b: Calculate the driving route distance to the closest train station using Google Maps API\n",
    "        route_distance = calculate_route_distance(coords, station_coords, gmaps)\n",
    "        rental_df_clean.loc[idx, 'route_distance_to_closest_train_km'] = route_distance\n",
    "\n",
    "    # Save progress every 100 rows\n",
    "    if (idx + 1) % 100 == 0:\n",
    "        print(f\"Processed {idx + 1} rows, saving progress...\")\n",
    "        rental_df_clean.to_csv(rental_data_path, index=False)\n",
    "\n",
    "# Final save after processing all data\n",
    "rental_df_clean.to_csv(rental_data_path, index=False)\n",
    "print(\"Processing completed.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
