{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESSING PROXIMITY**\n",
    "-----------\n",
    "\n",
    "In this notebook, we will calculate the proximity of some features that may affect housing prices.\n",
    "\n",
    "Features include proximity to:\n",
    "- CBD\n",
    "- Nearest Train Station\n",
    "- Nearest Shopping Precinct\n",
    "- Nearest Park (or reserve, national parks etc.)\n",
    "- Nearest Primary/Secondary School\n",
    "  - And the type of school\n",
    "\n",
    "All distances calculated are in km.\n",
    "\n",
    "Due to the large amount of data that is processed, we seperately save the features throughout this notebook as we add route distance through iterating and saving every 100 rows. If it runs fine, just save the bottom one as csv. If you had to restart the notebook, then load all the dfs to combine them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "import googlemaps\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "def feat_sf (shapefile, feature_name, feat_type = None, feat_subtypes = None):\n",
    "    \"\"\"\n",
    "    Cleaning shapefiles and dataframes for features we want.\n",
    "\n",
    "    Args:\n",
    "        shapefile (gpd.Geodataframe or pd.dataframe): the file with information on neighbourhood features\n",
    "        feature_name (str): name of the feature\n",
    "        feat_type (str or list, optional): any specific types of feature we want. Defaults to None.\n",
    "        feat_subtypes (list, optional): feature subtypes, for example, a chicken is a subtype of a bird . Defaults to None.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: feature name is wrong and not mentioned\n",
    "\n",
    "    Returns:\n",
    "        gpd.Geodataframe or pd.dataframe: the cleaned shapefile or dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    #Removing irrelevant features\n",
    "    if feature_name in (\"shopping\", \"parks\") and feat_type is not None and feat_subtypes is not None:\n",
    "        # We only want features in VIC\n",
    "        filtered_sf = shapefile[shapefile['STATE'] == \"VIC\"]\n",
    "        filtered_sf = filtered_sf[filtered_sf['FTYPE'] == feat_type]\n",
    "        filtered_sf = filtered_sf[filtered_sf['FEATSUBTYP'].isin(feat_subtypes)]\n",
    "        \n",
    "    elif feature_name == \"train_station\":\n",
    "        filtered_sf = shapefile[shapefile['STATUS'] == \"Active\"]\n",
    "        # Renaming columns for ease of use for future functions\n",
    "        filtered_sf = filtered_sf.rename(columns={'STATION': 'NAME'})\n",
    "    \n",
    "    elif feature_name in (\"primary_school\", \"secondary_school\") and feat_type is not None:\n",
    "        filtered_sf = shapefile[shapefile['School_Type'].isin(feat_type)]\n",
    "        # Renaming columns for ease of use for future functions\n",
    "        filtered_sf = filtered_sf.rename(columns={'School_Name': 'NAME'})\n",
    "        filtered_sf = filtered_sf.rename(columns={'Y': 'latitude'})\n",
    "        filtered_sf = filtered_sf.rename(columns={'X': 'longitude'})\n",
    "        \n",
    "        # As the df for school data is just a dataframe, we do not need to convert polygons into coordinates\n",
    "        return filtered_sf.reset_index(drop=True)\n",
    "    else:\n",
    "        # Handle cases where feature_name does not match any known types\n",
    "        raise ValueError(\"Invalid feature_name provided.\")\n",
    "        \n",
    "    # Setting shapefile format\n",
    "    filtered_sf['geometry'] = filtered_sf['geometry'].to_crs(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n",
    "    \n",
    "    # Creating an array of centroids of polygons in the feature shapefiles\n",
    "    filtered_sf['centroid'] = filtered_sf['geometry'].centroid.apply(lambda geom: (geom.y, geom.x))\n",
    "    filtered_sf['latitude'] = filtered_sf['centroid'].apply(lambda coord: coord[0])\n",
    "    filtered_sf['longitude'] = filtered_sf['centroid'].apply(lambda coord: coord[1])\n",
    "\n",
    "    return filtered_sf.reset_index(drop=True)\n",
    "\n",
    "def coord_radian_array (input_data):\n",
    "    \"\"\"\n",
    "    Creates a numpy array of radians to use for Haversine distance calculations\n",
    "\n",
    "    Args:\n",
    "        input_data (pd.DataFrame, gpd.GeoDataFrame, list or tuple): getting the coordinates from dataframe,\n",
    "                                                                    or converting the sole coordinate to an array\n",
    "\n",
    "    Raises:\n",
    "        ValueError: wrong type of input, or is not a single coordinate\n",
    "\n",
    "    Returns:\n",
    "        np.array: array of radians\n",
    "    \"\"\"\n",
    "    # Check if the input is a DataFrame using type()\n",
    "    if (type(input_data) == pd.DataFrame or type(input_data) == gpd.GeoDataFrame) and \\\n",
    "       (\"latitude\" in input_data.columns and \"longitude\" in input_data.columns):\n",
    "       # Convert the latitude and longitude to separate numpy arrays\n",
    "        lattitudes = np.radians(input_data['latitude'].to_numpy())\n",
    "        longtitudes = np.radians(input_data['longitude'].to_numpy())\n",
    "        \n",
    "        # Combine latitudes and longitudes into a 2D array of radians\n",
    "        coordinate = np.column_stack((lattitudes, longtitudes))\n",
    "    elif (type(input_data) == list or type(input_data) == tuple) and len(input_data) == 2:\n",
    "        # Turn the one coordinate into a 2D array, and turn it into a radian value\n",
    "        coordinate = np.radians(np.array([input_data]))\n",
    "    else:\n",
    "        # Error if unexpected type of data or does not have the appropiate columns\n",
    "        raise ValueError(\"Input must be a DataFrame with 'latitude' and 'longitude' columns or a \\\n",
    "                         list/tuple of coordinates [latitude, longitude].\")\n",
    "         \n",
    "    return coordinate\n",
    "\n",
    "def rental_haversine_closest(rental_df, feature_data, feature_name):\n",
    "    \"\"\"\n",
    "    Calculate the distance, and for features with multiple coordinates, picks the closest one.\n",
    "\n",
    "    Args:\n",
    "        rental_df (pd.DataFrame): Rental data and coordinates\n",
    "        feature_data (pd.DataFrame, gpd.GeoDataFrame, list or tuple): coordinates and info on features\n",
    "        feature_name (str): Name of feature\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: rental dataframe with info on distance and additional data\n",
    "    \"\"\"\n",
    "    global nearest_distance\n",
    "    \n",
    "    # Turning info into radian arrays\n",
    "    feat_radians = coord_radian_array(feature_data)\n",
    "    rental_radians = coord_radian_array(rental_df)\n",
    "\n",
    "    # Used Haversine distance as the earth's curve may affect distance \n",
    "    distances_radians = haversine_distances(feat_radians, rental_radians)\n",
    "    distances_km = distances_radians * 6371\n",
    "    \n",
    "    # If only one coordinate\n",
    "    if (type(feature_data) == list or type(feature_data) == tuple) and len(feature_data) == 2:\n",
    "        nearest_distance = distances_km[0, :] \n",
    "    \n",
    "    # If a set of coordinates\n",
    "    elif type(feature_data) == pd.DataFrame or type(feature_data) == gpd.GeoDataFrame:\n",
    "        # Grabbing the id of the nearest feature\n",
    "        nearest_point_id = np.argmin(distances_km, axis=0)\n",
    "        # Grabbing distance between the rental and the nearest feature\n",
    "        nearest_distance = np.min(distances_km, axis=0)\n",
    "\n",
    "        # Add the name, latitude, longitude and distance of the closest feature from the rental\n",
    "        rental_df[f'nearest_{feature_name}_name'] = feature_data.loc[nearest_point_id, 'NAME'].values\n",
    "        rental_df[f'nearest_{feature_name}_name'] = rental_df[f'nearest_{feature_name}_name'].str.title()\n",
    "        # If feautre is schools, add school type\n",
    "        if feature_name in (\"primary_school\", \"secondary_school\"):\n",
    "            rental_df[f'nearest_{feature_name}_type'] = feature_data.loc[nearest_point_id, 'Education_Sector'].values\n",
    "        rental_df[f'nearest_{feature_name}_latitude'] = feature_data.loc[nearest_point_id, 'latitude'].values\n",
    "        rental_df[f'nearest_{feature_name}_longitude'] = feature_data.loc[nearest_point_id, 'longitude'].values\n",
    "\n",
    "    # Add distance  \n",
    "    rental_df[f'straight_line_distance_{feature_name}'] = nearest_distance\n",
    "    return rental_df\n",
    "\n",
    "# Calculate the driving route distance using Google Maps API\n",
    "def calculate_route_distance(property_coords, destination_coords, gmaps_client):\n",
    "    \"\"\"\n",
    "    Uses google maps api to look up the route distance in km\n",
    "\n",
    "    Args:\n",
    "        property_coords (float): coordinates of the rental property\n",
    "        destination_coords (float): coordinates of the feature/desitnation\n",
    "        gmaps_client (API): google maps API connection\n",
    "\n",
    "    Returns:\n",
    "        int: route distance in km\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Request the driving distance between the property and the closest train station\n",
    "        result = gmaps_client.distance_matrix(origins=[property_coords], destinations=[destination_coords], mode=\"driving\")\n",
    "        \n",
    "        # Check if the result is valid\n",
    "        if result['rows'][0]['elements'][0]['status'] == 'OK':\n",
    "            distance = result['rows'][0]['elements'][0]['distance']['value']  # Distance in meters\n",
    "            return distance / 1000  # Convert from meters to kilometers\n",
    "        else:\n",
    "            print(f\"No valid route distance found for {property_coords} to {destination_coords}: {result['rows'][0]['elements'][0]['status']}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating route distance for {property_coords}: {e}\")\n",
    "        return None\n",
    "\n",
    "def route_dist_and_save_csv(rental_df, feature_name, single_dest_coord = None):\n",
    "    \"\"\"\n",
    "    Iterate through rows of a rental_df, then apply route (driving distance) calculation from\n",
    "    each rental property to each feature in km.\n",
    "\n",
    "    Args:\n",
    "        rental_df (pd.dataframe): cleaned rental df with the closest feature listed with haversine distance\n",
    "        feature_name (str): name of feature to save as\n",
    "        single_dest_coord (_type_, optional): _description_. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.dataframe: final rental df with route distance calculated\n",
    "    \"\"\"\n",
    "    # Create null column\n",
    "    rental_df[f'route_distance_{feature_name}'] = np.nan\n",
    "\n",
    "    # Iterate through each row \n",
    "    for index, rental in rental_df.iterrows():\n",
    "        # Sacing coordinate\n",
    "        property_coord = (rental['latitude'], rental['longitude'])\n",
    "        if single_dest_coord != None:\n",
    "            feat_coord = tuple(single_dest_coord)\n",
    "        else:\n",
    "            feat_coord = (rental[f'nearest_{feature_name}_latitude'], rental[f'nearest_{feature_name}_longitude'])\n",
    "        # Calculate route distance\n",
    "        route_distance = calculate_route_distance(property_coord, feat_coord, gmaps)\n",
    "        rental_df.at[index, f'route_distance_{feature_name}'] = route_distance\n",
    "        \n",
    "        if (index + 1) % 100 == 0:\n",
    "            print(f\"Processed {index + 1} rows, saving progress...\")\n",
    "            rental_df.to_csv(f\"{curated_dir}rental_with_{feature_name}.csv\", index=False)\n",
    "            \n",
    "    # Final save after processing all data\n",
    "    rental_df.to_csv(f\"{curated_dir}rental_with_{feature_name}.csv\", index=False)\n",
    "    return rental_df\n",
    "\n",
    "\n",
    "# Initialize the Google Maps API client with  API key\n",
    "google_apikey = 'your key'\n",
    "gmaps = googlemaps.Client(key = google_apikey)\n",
    "\n",
    "# Directories\n",
    "data_dir = '../data/'\n",
    "landing_dir = data_dir + 'landing/'\n",
    "raw_dir = data_dir + 'raw/'\n",
    "curated_dir = data_dir + 'curated/'\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adds coordinates for each rental property to the rental scrape.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding coordinates for each address\n",
    "rental_df = pd.read_csv(f\"{landing_dir}rental_scrape.csv\")\n",
    "\n",
    "# Step 1: Initialize Nominatim geocoder with retry logic\n",
    "geolocator = Nominatim(user_agent=\"rental_geocoder\", timeout=10)\n",
    "\n",
    "# Create a session with retry settings to handle temporary errors\n",
    "session = requests.Session()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])\n",
    "adapter = HTTPAdapter(max_retries=retries)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "\n",
    "# Step 2: Function to geocode addresses with retries\n",
    "def geocode_address(address):\n",
    "    try:\n",
    "        location = geolocator.geocode(address, timeout=10)\n",
    "        if location:\n",
    "            return (location.latitude, location.longitude)\n",
    "        else:\n",
    "            return (None, None)\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {address}: {e}\")\n",
    "        return (None, None)\n",
    "\n",
    "# Step 3: Apply geocoding function to the 'Address' column with retry logic\n",
    "rental_coord = rental_df['Address'].apply(lambda address: geocode_address(address))\n",
    "\n",
    "# Step 4: Split coordinates into 'latitude' and 'longitude' columns\n",
    "rental_df['latitude'] = rental_coord.apply(lambda x: x[0])\n",
    "rental_df['longitude'] = rental_coord.apply(lambda x: x[1])\n",
    "\n",
    "# Step 5: Filter out rows where latitude or longitude is NaN\n",
    "cleaned_rental_df = rental_df.dropna(subset=['latitude', 'longitude']).copy()\n",
    "cleaned_rental_df = cleaned_rental_df.reset_index(drop=True)\n",
    "cleaned_rental_df = cleaned_rental_df.drop(columns= [\"URL\", \"Name\"])\n",
    "\n",
    "# Step 6: Save the DataFrame with geocoded coordinates to a new CSV\n",
    "cleaned_rental_df.to_csv(f'{raw_dir}rental_with_coordinates.csv', index=False)\n",
    "\n",
    "# Add a small delay between requests to avoid being blocked by Nominatim API\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding proximity of the rental property to CDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_rental_df = pd.read_csv(f\"{raw_dir}rental_with_coordinates.csv\")\n",
    "cbd_feature = \"CBD\"\n",
    "\n",
    "# Coordinates for Melbourne CBD (latitude, longitude for Google Maps)\n",
    "melbourne_cbd_coords = [-37.8136, 144.9631]\n",
    "feature_data = melbourne_cbd_coords\n",
    "\n",
    "# Get straight line distance between Melbourne CBD and the rental\n",
    "cbd_haversine_df = rental_haversine_closest(cleaned_rental_df, melbourne_cbd_coords, cbd_feature)\n",
    "# Save incrementally in a file, just in case. Combine later. \n",
    "cbd_rental_df = route_dist_and_save_csv(cbd_haversine_df, cbd_feature, melbourne_cbd_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding proximity of the rental property to their closest train station**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptv_sf = gpd.read_file(f\"{landing_dir}PTV/VIC_RAILWAY_STATIONS.shp\")\n",
    "train_station_feature = \"train_station\"\n",
    "\n",
    "# Processing the shapefile for information we need\n",
    "train_station_sf = feat_sf(ptv_sf, train_station_feature)\n",
    "# Get closest station, and the straight line distance between Melbourne CBD and the rental\n",
    "train_station_haversine_df = rental_haversine_closest(cleaned_rental_df, train_station_sf, train_station_feature)\n",
    "train_station_rental_df = route_dist_and_save_csv(train_station_haversine_df, train_station_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding proximity of the rental property to their closest shopping precinct and park**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping_parks_foi_sf = gpd.read_file(f\"{landing_dir}FOI/GEOMARK_POLYGON.shp\")\n",
    "\n",
    "shopping_type = \"commercial facility\"\n",
    "shopping_feature = \"shopping\"\n",
    "shopping_labels = [\"shopping precinct\", \"shopping centre\"]\n",
    "\n",
    "shopping_sf = feat_sf(shopping_parks_foi_sf, shopping_feature, shopping_type, shopping_labels)\n",
    "shopping_haversine_df = rental_haversine_closest(cleaned_rental_df, shopping_sf, shopping_feature)\n",
    "shopping_rental_df = route_dist_and_save_csv(shopping_haversine_df, shopping_feature)\n",
    "\n",
    "parks_type = \"reserve\"\n",
    "parks_feature = \"parks\"\n",
    "parks_labels = [\"park\", \"conservation park\", \"gardens\", \"national park\", \"city square\"]\n",
    "\n",
    "parks_sf = feat_sf(shopping_parks_foi_sf, parks_feature, parks_type, parks_labels)\n",
    "parks_haversine_df = rental_haversine_closest(cleaned_rental_df, parks_sf, parks_feature)\n",
    "parks_rental_df = route_dist_and_save_csv(parks_haversine_df, parks_feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding proximity of the rental property to their closest primary and secondary school**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_df = pd.read_csv(f\"{landing_dir}dv346-schoollocations2023.csv\", encoding = \"ISO-8859-1\")\n",
    "\n",
    "primary_school_type = [\"Primary\", \"Pri/Sec\"]\n",
    "primary_school_feautre = \"primary_school\"\n",
    "\n",
    "primary_school_df = feat_sf(school_df, primary_school_feautre, primary_school_type)\n",
    "primary_school_haversine_df = rental_haversine_closest(cleaned_rental_df, primary_school_df, primary_school_feautre)\n",
    "primary_school_rental_df = route_dist_and_save_csv(primary_school_haversine_df, primary_school_feautre)\n",
    "\n",
    "secondary_school_type = [\"secondary\", \"Pri/Sec\"]\n",
    "secondary_school_feautre = \"secondary_school\"\n",
    "\n",
    "secondary_school_df = feat_sf(school_df, secondary_school_feautre, secondary_school_type)\n",
    "secondary_school_df = feat_sf(school_df, secondary_school_feautre, secondary_school_type)\n",
    "secondary_school_haversine_df = rental_haversine_closest(cleaned_rental_df, secondary_school_df, secondary_school_feautre)\n",
    "secondary_school_rental_df = route_dist_and_save_csv(secondary_school_haversine_df, secondary_school_feautre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining and saving all features and their distances into one single dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If restart notebook\n",
    "\"\"\"\n",
    "# Redownloading dfs just in case\n",
    "# cleaned_rental_df = pd.read_csv(f\"{raw_dir}rental_with_coordinates.csv\")\n",
    "# cbd_rental_df = pd.read_csv(f\"{curated_dir}rental_with_CBD.csv\")\n",
    "# train_station_rental_df = pd.read_csv(f\"{curated_dir}rental_with_train_station.csv\")\n",
    "# shopping_rental_df = pd.read_csv(f\"{curated_dir}rental_with_shopping.csv\")\n",
    "# parks_rental_df = pd.read_csv(f\"{curated_dir}rental_with_parks.csv\")\n",
    "# primary_school_rental_df = pd.read_csv(f\"{curated_dir}rental_with_primary_school.csv\")\n",
    "# secondary_school_rental_df = pd.read_csv(f\"{curated_dir}rental_with_secondary_school.csv\")\n",
    "\n",
    "# columns_to_remove = cleaned_rental_df.columns\n",
    "\n",
    "# # Dropping common columns\n",
    "# train_station_rental_df = train_station_rental_df.drop(columns=columns_to_remove)\n",
    "# shopping_rental_df = shopping_rental_df.drop(columns=columns_to_remove)\n",
    "# parks_rental_df = parks_rental_df.drop(columns=columns_to_remove)\n",
    "# primary_school_rental_df = primary_school_rental_df.drop(columns=columns_to_remove)\n",
    "# secondary_school_rental_df = secondary_school_rental_df.drop(columns=columns_to_remove)\n",
    "\n",
    "# # Combining all columns\n",
    "# combined_df = pd.concat([cbd_rental_df, train_station_rental_df, shopping_rental_df, parks_rental_df, \n",
    "#                          primary_school_rental_df, secondary_school_rental_df])\n",
    "\n",
    "# Save as csv\n",
    "# combined_df.to_csv(f\"{curated_dir}rental_with_all_features.csv\", index=False)\n",
    "\n",
    "\"\"\"\n",
    "If no need to restart notebook\n",
    "\"\"\"\n",
    "# Save as csv\n",
    "cleaned_rental_df.to_csv(f\"{curated_dir}rental_with_all_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
