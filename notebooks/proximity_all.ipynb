{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "import googlemaps\n",
    "\n",
    "def feat_sf (shapefile, feat_type, feat_subtypes):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        shapefile (_type_): _description_\n",
    "        feat_type (_type_): _description_\n",
    "        feat_subtypes (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # Removing irrelevant features, as we only want features in VIC\n",
    "    filtered_sf = shapefile[shapefile['STATE'] == \"VIC\"]\n",
    "    filtered_sf = filtered_sf[filtered_sf['FTYPE'] == feat_type]\n",
    "    filtered_sf = filtered_sf[filtered_sf['FEATSUBTYP'].isin(feat_subtypes)]\n",
    "    filtered_sf = filtered_sf.reset_index(drop=True)\n",
    "    \n",
    "    # Setting shapefile format\n",
    "    filtered_sf['geometry'] = filtered_sf['geometry'].to_crs(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n",
    "    \n",
    "    # Creating an array of centroids of polygons in the feature shapefiles\n",
    "    filtered_sf['centroid'] = filtered_sf['geometry'].centroid.apply(lambda geom: (geom.y, geom.x))\n",
    "    filtered_sf['latitude'] = filtered_sf['centroid'].apply(lambda coord: coord[0])\n",
    "    filtered_sf['longitude'] = filtered_sf['centroid'].apply(lambda coord: coord[1])\n",
    "\n",
    "    return filtered_sf\n",
    "\n",
    "def rental_feat_haversine_closest(rental_df, filtered_sf, feature_name):\n",
    "    # Convert the latitude and longitude to separate numpy arrays\n",
    "    feat_latitudes = np.radians(filtered_sf['latitude'].to_numpy())\n",
    "    feat_longitudes = np.radians(filtered_sf['longitude'].to_numpy())\n",
    "    rental_latitudes = np.radians(rental_df['latitude'].to_numpy())\n",
    "    rental_longitudes = np.radians(rental_df['longitude'].to_numpy())\n",
    "\n",
    "    # Combine latitudes and longitudes into a 2D array of radians\n",
    "    feat_centroid_radians = np.column_stack((feat_latitudes, feat_longitudes))\n",
    "    rental_centroid_radians = np.column_stack((rental_latitudes, rental_longitudes))\n",
    "\n",
    "    # Used Haversine distance as the earth's curve may affect distance \n",
    "    distances_radians = haversine_distances(feat_centroid_radians, rental_centroid_radians)\n",
    "    distances_km = distances_radians * 6371\n",
    "    \n",
    "    # Grabbing the id of the nearest feature\n",
    "    nearest_point_id = np.argmin(distances_km, axis=0)\n",
    "    # Grabbing distance between the rental and the nearest feature\n",
    "    nearest_distance = np.min(distances_km, axis=0)\n",
    "\n",
    "    # Add the name, latitude, longitude and distance of the closest feature from the rental\n",
    "    rental_df[f'nearest_{feature_name}_name'] = filtered_sf.loc[nearest_point_id, 'NAME'].values\n",
    "    rental_df[f'nearest_{feature_name}_latitude'] = filtered_sf.loc[nearest_point_id, 'latitude'].values\n",
    "    rental_df[f'nearest_{feature_name}_longitude'] = filtered_sf.loc[nearest_point_id, 'longitude'].values\n",
    "    rental_df[f'straight_line_distance_{feature_name}'] = nearest_distance\n",
    "    return rental_df\n",
    "\n",
    "# Calculate the driving route distance using Google Maps API\n",
    "def calculate_route_distance(property_coords, destination_coords, gmaps_client):\n",
    "    try:\n",
    "        # Request the driving distance between the property and the closest train station\n",
    "        result = gmaps_client.distance_matrix(origins=[property_coords], destinations=[destination_coords], mode=\"driving\")\n",
    "        \n",
    "        # Check if the result is valid\n",
    "        if result['rows'][0]['elements'][0]['status'] == 'OK':\n",
    "            distance = result['rows'][0]['elements'][0]['distance']['value']  # Distance in meters\n",
    "            return distance / 1000  # Convert from meters to kilometers\n",
    "        else:\n",
    "            print(f\"No valid route distance found for {property_coords} to {destination_coords}: {result['rows'][0]['elements'][0]['status']}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating route distance for {property_coords}: {e}\")\n",
    "        return None\n",
    "\n",
    "def route_dist_and_save_csv(rental_df, feature_name):\n",
    "    rental_df[f'route_distance_{feature_name}'] = np.nan\n",
    "\n",
    "    for index, rental in rental_df.iterrows():\n",
    "        property_coord = (rental['latitude'], rental['longitude'])\n",
    "        feat_coord = (rental[f'nearest_{feature_name}_latitude'], rental[f'nearest_{feature_name}_longitude'])\n",
    "        route_distance = calculate_route_distance(property_coord, feat_coord, gmaps)\n",
    "        rental_df.at[index, f'route_distance_{feature_name}'] = route_distance\n",
    "        \n",
    "        if (index + 1) % 100 == 0:\n",
    "            print(f\"Processed {index + 1} rows, saving progress...\")\n",
    "            rental_df.to_csv(f\"{curated_dir}rental_with_{feature_name}.csv\", index=False)\n",
    "    return rental_df\n",
    "\n",
    "\n",
    "# Initialize the Google Maps API client with  API key\n",
    "google_apikey = 'your_key'\n",
    "gmaps = googlemaps.Client(key = google_apikey)\n",
    "\n",
    "# Directories\n",
    "data_dir = '../data/'\n",
    "landing_dir = data_dir + 'landing/'\n",
    "raw_dir = data_dir + 'raw/'\n",
    "curated_dir = data_dir + 'curated/'\n",
    "\n",
    "# Download files\n",
    "shopping_parks_foi_sf = gpd.read_file(f\"{landing_dir}FOI/GEOMARK_POLYGON.shp\")\n",
    "rental_df = pd.read_csv(f\"{raw_dir}rental_with_coordinates.csv\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Filter out rows where latitude or longitude is NaN\n",
    "cleaned_rental_df = rental_df.dropna(subset=['latitude', 'longitude']).copy()\n",
    "cleaned_rental_df = cleaned_rental_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the distance column if not already present\n",
    "cleaned_rental_df['distance_to_cbd_km'] = None\n",
    "\n",
    "# Coordinates for Melbourne CBD (latitude, longitude for Google Maps)\n",
    "melbourne_cbd_coords = [-37.8136, 144.9631]\n",
    "\n",
    "# Step 3: Apply the distance calculation for each rental property\n",
    "cleaned_rental_df['coordinates'] = cleaned_rental_df.apply(lambda row: (row['latitude'], row['longitude']), axis=1)\n",
    "feature_name = \"cbd_distances\"\n",
    "\n",
    "# Step 4: Process each property and save progress incrementally\n",
    "for idx, row in cleaned_rental_df.iterrows():\n",
    "    if pd.isnull(row['distance_to_cbd_km']):  # Only process rows with null distances\n",
    "        coords = row['coordinates']\n",
    "        if coords:  # Ensure the coordinates are valid\n",
    "            distance = calculate_route_distance(coords, melbourne_cbd_coords, gmaps)\n",
    "            cleaned_rental_df.loc[idx, 'distance_to_cbd_km'] = distance\n",
    "\n",
    "    # Save progress every 100 rows\n",
    "    if (idx + 1) % 100 == 0:\n",
    "        print(f\"Processed {idx + 1} rows, saving progress...\")\n",
    "        cleaned_rental_df.to_csv(f\"{curated_dir}rental_with_{feature_name}.csv\", index=False)\n",
    "\n",
    "# Final save after processing all data\n",
    "cleaned_rental_df.to_csv(f\"{curated_dir}rental_with_{feature_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "shopping_type = \"commercial facility\"\n",
    "shopping_feature = \"shopping\"\n",
    "shopping_labels = [\"shopping precinct\", \"shopping centre\"]\n",
    "\n",
    "shopping_sf = feat_sf(shopping_parks_foi_sf, shopping_type, shopping_labels)\n",
    "shopping_haversine_df = rental_feat_haversine_closest(cleaned_rental_df, shopping_sf, shopping_feature)\n",
    "shopping_rental_df = route_dist_and_save_csv(shopping_haversine_df, shopping_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_type = \"reserve\"\n",
    "parks_feature = \"parks\"\n",
    "parks_labels = [\"park\", \"conservation park\", \"gardens\", \"national park\", \"city square\"]\n",
    "\n",
    "parks_sf = feat_sf(shopping_parks_foi_sf, parks_type, parks_labels)\n",
    "parks_haversine_df = rental_feat_haversine_closest(cleaned_rental_df, parks_sf, parks_feature)\n",
    "parks_rental_df = route_dist_and_save_csv(parks_haversine_df, parks_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_cbd_train_df = pd.read_csv(f\"{curated_dir}rental_distances_cbd_trains_schools.csv\")\n",
    "parks_df = pd.read_csv(f\"{curated_dir}rental_with_parks.csv\")\n",
    "shopping_df = pd.read_csv(f\"{curated_dir}rental_with_shopping.csv\")\n",
    "similar_cols = list(rental_df.columns)\n",
    "combined_parks_shopping = pd.merge(parks_df, shopping_df, left_on=similar_cols, right_on=similar_cols)\n",
    "school_cbd_train_df = school_cbd_train_df.drop_duplicates(subset=['coordinates', 'latitude', 'longitude'])\n",
    "combined_all = pd.merge(combined_parks_shopping, school_cbd_train_df, \n",
    "                        how = 'inner',\n",
    "                        left_on=['coordinates', 'latitude', 'longitude'], \n",
    "                        right_on=['coordinates', 'latitude','longitude'])\n",
    "cleaned_combined_all = combined_all.drop(['Unnamed: 0', 'Cost_y', 'Beds', 'Baths', 'Cars', 'Address_y','Property Type'], axis=1)\n",
    "cleaned_combined_all.columns\n",
    "cleaned_combined_all.rename(columns={'Cost_x': 'Cost', 'Address_x': 'Address'}, inplace=True)\n",
    "cleaned_combined_all['nearest_parks_name'] = cleaned_combined_all['nearest_parks_name'].str.title()\n",
    "cleaned_combined_all['nearest_shopping_name'] = cleaned_combined_all['nearest_shopping_name'].str.title()\n",
    "\n",
    "cleaned_combined_all.to_csv(f\"{curated_dir}combined_rental_features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
