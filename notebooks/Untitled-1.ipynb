{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Directories\n",
    "data_dir = '../data/'\n",
    "landing_dir = data_dir + 'landing/'\n",
    "raw_dir = data_dir + 'raw/'\n",
    "curated_dir = data_dir + 'curated/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gd/m0kqkz893_x6z1pmcms3kw_r0000gn/T/ipykernel_3924/2013080291.py:48: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  filtered_sf['centroid'] = filtered_sf['geometry'].centroid.apply(lambda geom: (geom.y, geom.x))\n",
      "/var/folders/gd/m0kqkz893_x6z1pmcms3kw_r0000gn/T/ipykernel_3924/2013080291.py:48: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  filtered_sf['centroid'] = filtered_sf['geometry'].centroid.apply(lambda geom: (geom.y, geom.x))\n",
      "/var/folders/gd/m0kqkz893_x6z1pmcms3kw_r0000gn/T/ipykernel_3924/2013080291.py:48: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  filtered_sf['centroid'] = filtered_sf['geometry'].centroid.apply(lambda geom: (geom.y, geom.x))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def feat_sf (shapefile, feature_name, feat_type = None, feat_subtypes = None):\n",
    "    \"\"\"\n",
    "    Cleaning shapefiles and dataframes for features we want.\n",
    "\n",
    "    Args:\n",
    "        shapefile (gpd.Geodataframe or pd.dataframe): the file with information on neighbourhood features\n",
    "        feature_name (str): name of the feature\n",
    "        feat_type (str or list, optional): any specific types of feature we want. Defaults to None.\n",
    "        feat_subtypes (list, optional): feature subtypes, for example, a chicken is a subtype of a bird . Defaults to None.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: feature name is wrong and not mentioned\n",
    "\n",
    "    Returns:\n",
    "        gpd.Geodataframe or pd.dataframe: the cleaned shapefile or dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    #Removing irrelevant features\n",
    "    if feature_name in (\"shopping\", \"parks\", \"hospital\") and feat_type is not None and feat_subtypes is not None:\n",
    "        # We only want features in VIC\n",
    "        filtered_sf = shapefile[shapefile['STATE'] == \"VIC\"]\n",
    "        filtered_sf = filtered_sf[filtered_sf['FTYPE'] == feat_type]\n",
    "        filtered_sf = filtered_sf[filtered_sf['FEATSUBTYP'].isin(feat_subtypes)]\n",
    "        \n",
    "    elif feature_name == \"train_station\":\n",
    "        filtered_sf = shapefile[shapefile['STATUS'] == \"Active\"]\n",
    "        # Renaming columns for ease of use for future functions\n",
    "        filtered_sf = filtered_sf.rename(columns={'STATION': 'NAME'})\n",
    "    \n",
    "    elif feature_name in (\"primary_school\", \"secondary_school\") and feat_type is not None:\n",
    "        filtered_sf = shapefile[shapefile['School_Type'].isin(feat_type)]\n",
    "        # Renaming columns for ease of use for future functions\n",
    "        filtered_sf = filtered_sf.rename(columns={'School_Name': 'NAME'})\n",
    "        filtered_sf = filtered_sf.rename(columns={'Y': 'latitude'})\n",
    "        filtered_sf = filtered_sf.rename(columns={'X': 'longitude'})\n",
    "        filtered_sf = filtered_sf.dropna(subset=['latitude', 'longitude']).copy()\n",
    "        \n",
    "        # As the df for school data is just a dataframe, we do not need to convert polygons into coordinates\n",
    "        return filtered_sf.reset_index(drop=True)\n",
    "    else:\n",
    "        # Handle cases where feature_name does not match any known types\n",
    "        raise ValueError(\"Invalid feature_name provided.\")\n",
    "        \n",
    "    # Setting shapefile format\n",
    "    filtered_sf['geometry'] = filtered_sf['geometry'].to_crs(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n",
    "    \n",
    "    # Creating an array of centroids of polygons in the feature shapefiles\n",
    "    filtered_sf['centroid'] = filtered_sf['geometry'].centroid.apply(lambda geom: (geom.y, geom.x))\n",
    "    filtered_sf['latitude'] = filtered_sf['centroid'].apply(lambda coord: coord[0])\n",
    "    filtered_sf['longitude'] = filtered_sf['centroid'].apply(lambda coord: coord[1])\n",
    "    filtered_sf = filtered_sf.dropna(subset=['latitude', 'longitude']).copy()\n",
    "\n",
    "    return filtered_sf.reset_index(drop=True)  \n",
    "    \n",
    "foi_sf = gpd.read_file(f\"{landing_dir}FOI/GEOMARK_POLYGON.shp\")\n",
    "\n",
    "shopping_type = \"commercial facility\"\n",
    "shopping_feature = \"shopping\"\n",
    "shopping_labels = [\"shopping precinct\", \"shopping centre\"]\n",
    "\n",
    "shopping_sf = feat_sf(foi_sf, shopping_feature, shopping_type, shopping_labels)\n",
    "\n",
    "parks_type = \"reserve\"\n",
    "parks_feature = \"parks\"\n",
    "parks_labels = [\"park\", \"conservation park\", \"gardens\", \"national park\", \"city square\"]\n",
    "\n",
    "parks_sf = feat_sf(foi_sf, parks_feature, parks_type, parks_labels)\n",
    "\n",
    "hospital_type = \"hospital\"\n",
    "hospital_feature = \"hospital\"\n",
    "hospital_labels = [\"hospital complex\"]\n",
    "\n",
    "hospital_sf = feat_sf(foi_sf, hospital_feature, hospital_type, hospital_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gd/m0kqkz893_x6z1pmcms3kw_r0000gn/T/ipykernel_3924/2295184268.py:8: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs + ...\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  features_in_sa2 = gpd.sjoin(feature_gdf, victoria_gdf, how='inner', predicate='within')\n",
      "/var/folders/gd/m0kqkz893_x6z1pmcms3kw_r0000gn/T/ipykernel_3924/2295184268.py:8: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs + ...\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  features_in_sa2 = gpd.sjoin(feature_gdf, victoria_gdf, how='inner', predicate='within')\n",
      "/var/folders/gd/m0kqkz893_x6z1pmcms3kw_r0000gn/T/ipykernel_3924/2295184268.py:8: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs + ...\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  features_in_sa2 = gpd.sjoin(feature_gdf, victoria_gdf, how='inner', predicate='within')\n"
     ]
    }
   ],
   "source": [
    "sa2_path = f'{data_dir}sa2_shapefile/SA2_2021_AUST_GDA2020.shp'\n",
    "gdf = gpd.read_file(sa2_path)\n",
    "victoria_gdf = gdf[gdf['STE_CODE21'] == '2']\n",
    "victoria_gdf = victoria_gdf.to_crs(epsg=4326)\n",
    "\n",
    "def feature_vic_merge(feature_gdf, victoria_gdf, feature_name):\n",
    "    # Perform a spatial join to assign each {feature_name} to its respective SA2 area (use 'predicate' instead of 'op')\n",
    "    features_in_sa2 = gpd.sjoin(feature_gdf, victoria_gdf, how='inner', predicate='within')\n",
    "\n",
    "    # Count the number of features in each SA2 area\n",
    "    features_per_sa2 = features_in_sa2.groupby('SA2_NAME21').size().reset_index(name=f'{feature_name}_count')\n",
    "\n",
    "    # Merge the {feature_name} counts with the Victoria SA2 GeoDataFrame\n",
    "    victoria_gdf = victoria_gdf.merge(features_per_sa2, on='SA2_NAME21', how='left')\n",
    "\n",
    "    # Fill NaN values with 0 (areas with no features)\n",
    "    victoria_gdf[f'{feature_name}_count'] = victoria_gdf[f'{feature_name}_count'].fillna(0)\n",
    "    return victoria_gdf.to_crs(epsg=4326)\n",
    "\n",
    "shopping_victoria_gdf = feature_vic_merge(shopping_sf, victoria_gdf, shopping_feature)\n",
    "parks_victoria_gdf = feature_vic_merge(parks_sf, victoria_gdf, parks_feature)\n",
    "hospital_victoria_gdf = feature_vic_merge(hospital_sf, victoria_gdf, hospital_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping_victoria_gdf.to_csv(f\"{data_dir}{shopping_feature}_count.csv\", index=False)\n",
    "parks_victoria_gdf.to_csv(f\"{data_dir}{parks_feature}_count.csv\", index=False)\n",
    "hospital_victoria_gdf.to_csv(f\"{data_dir}{hospital_feature}_count.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
