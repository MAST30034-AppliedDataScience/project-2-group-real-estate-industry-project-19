{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESSING PROXIMITY**\n",
    "-----------\n",
    "\n",
    "In this notebook, we will calculate the proximity of some features that may affect housing prices.\n",
    "\n",
    "Features include proximity to:\n",
    "- CBD\n",
    "- Nearest Train Station\n",
    "- Nearest Shopping Precinct\n",
    "- Nearest Park (or reserve, national parks etc.)\n",
    "- Nearest Hospital\n",
    "- Nearest Primary/Secondary School\n",
    "  - And the type of school\n",
    "\n",
    "All distances calculated are in km.\n",
    "\n",
    "Due to the large amount of data that is processed, we seperately save the features throughout this notebook as we add route distance through iterating and saving every 100 rows. If it runs fine, just save the bottom one as csv. If you had to restart the notebook, then load all the dfs to combine them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import googlemaps\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import scripts\n",
    "import importlib\n",
    "importlib.reload(scripts)\n",
    "from scripts.preprocess_proximity import *\n",
    "\n",
    "# Initialize the Google Maps API client with  API key\n",
    "google_apikey = 'your_key'\n",
    "gmaps = googlemaps.Client(key = google_apikey)\n",
    "\n",
    "# Directories\n",
    "data_dir = '../data/'\n",
    "landing_dir = data_dir + 'landing/'\n",
    "raw_dir = data_dir + 'raw/'\n",
    "curated_dir = data_dir + 'curated/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adds coordinates for each rental property to the rental scrape.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding coordinates for each address\n",
    "rental_df = pd.read_csv(f\"{landing_dir}rental_scrape.csv\")\n",
    "\n",
    "# Step 1: Initialize Nominatim geocoder with retry logic\n",
    "geolocator = Nominatim(user_agent=\"rental_geocoder\", timeout=10)\n",
    "\n",
    "# Create a session with retry settings to handle temporary errors\n",
    "session = requests.Session()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])\n",
    "adapter = HTTPAdapter(max_retries=retries)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "\n",
    "# Step 2: Function to geocode addresses with retries\n",
    "def geocode_address(address):\n",
    "    try:\n",
    "        location = geolocator.geocode(address, timeout=10)\n",
    "        if location:\n",
    "            return (location.latitude, location.longitude)\n",
    "        else:\n",
    "            return (None, None)\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {address}: {e}\")\n",
    "        return (None, None)\n",
    "\n",
    "# Step 3: Apply geocoding function to the 'Address' column with retry logic\n",
    "rental_coord = rental_df['Address'].apply(lambda address: geocode_address(address))\n",
    "\n",
    "# Step 4: Split coordinates into 'latitude' and 'longitude' columns\n",
    "rental_df['latitude'] = rental_coord.apply(lambda x: x[0])\n",
    "rental_df['longitude'] = rental_coord.apply(lambda x: x[1])\n",
    "\n",
    "# Step 5: Filter out rows where latitude or longitude is NaN\n",
    "cleaned_rental_df = rental_df.dropna(subset=['latitude', 'longitude']).copy()\n",
    "cleaned_rental_df = cleaned_rental_df.reset_index(drop=True)\n",
    "cleaned_rental_df = cleaned_rental_df.drop(columns= [\"URL\", \"Name\"])\n",
    "\n",
    "# Step 6: Save the DataFrame with geocoded coordinates to a new CSV\n",
    "cleaned_rental_df.to_csv(f'{raw_dir}rental_with_coordinates.csv', index=False)\n",
    "\n",
    "# Add a small delay between requests to avoid being blocked by Nominatim API\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding proximity of the rental property to CDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_rental_df = pd.read_csv(f\"{raw_dir}rental_with_coordinates.csv\")\n",
    "cbd_feature = \"CBD\"\n",
    "\n",
    "# Coordinates for Melbourne CBD (latitude, longitude for Google Maps)\n",
    "melbourne_cbd_coords = [-37.8136, 144.9631]\n",
    "feature_data = melbourne_cbd_coords\n",
    "\n",
    "# Get straight line distance between Melbourne CBD and the rental\n",
    "cbd_haversine_df = rental_haversine_closest(cleaned_rental_df, melbourne_cbd_coords, cbd_feature)\n",
    "# Save incrementally in a file, just in case. Combine later. \n",
    "cbd_rental_df = route_dist_and_save_csv(cbd_haversine_df, cbd_feature, curated_dir, gmaps, melbourne_cbd_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding proximity of the rental property to their closest train station**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptv_sf = gpd.read_file(f\"{landing_dir}PTV/VIC_RAILWAY_STATIONS.shp\")\n",
    "train_station_feature = \"train_station\"\n",
    "\n",
    "# Processing the shapefile for information we need\n",
    "train_station_sf = feat_sf(ptv_sf, train_station_feature)\n",
    "# Get closest station, and the straight line distance between Melbourne CBD and the rental\n",
    "train_station_haversine_df = rental_haversine_closest(cleaned_rental_df, train_station_sf, train_station_feature)\n",
    "train_station_rental_df = route_dist_and_save_csv(train_station_haversine_df, train_station_feature, curated_dir, gmaps)\n",
    "\n",
    "\n",
    "# route_dist_and_save_csv(rental_df, feature_name, save_to_dir, gmaps_client, single_dest_coord = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding proximity of the rental property to their closest shopping precinct, park/reserve and hospital**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foi_sf = gpd.read_file(f\"{landing_dir}FOI/GEOMARK_POLYGON.shp\")\n",
    "cleaned_rental_df = pd.read_csv(f\"{raw_dir}rental_with_coordinates.csv\")\n",
    "cleaned_rental_df = cleaned_rental_df.dropna(subset=['latitude', 'longitude']).copy()\n",
    "\n",
    "shopping_type = \"commercial facility\"\n",
    "shopping_feature = \"shopping\"\n",
    "shopping_labels = [\"shopping precinct\", \"shopping centre\"]\n",
    "\n",
    "shopping_sf = feat_sf(foi_sf, shopping_feature, shopping_type, shopping_labels)\n",
    "shopping_haversine_df = rental_haversine_closest(cleaned_rental_df, shopping_sf, shopping_feature)\n",
    "shopping_rental_df = route_dist_and_save_csv(shopping_haversine_df, shopping_feature, curated_dir, gmaps)\n",
    "\n",
    "parks_type = \"reserve\"\n",
    "parks_feature = \"parks\"\n",
    "parks_labels = [\"park\", \"conservation park\", \"gardens\", \"national park\", \"city square\"]\n",
    "\n",
    "parks_sf = feat_sf(foi_sf, parks_feature, parks_type, parks_labels)\n",
    "parks_haversine_df = rental_haversine_closest(cleaned_rental_df, parks_sf, parks_feature)\n",
    "parks_rental_df = route_dist_and_save_csv(parks_haversine_df, parks_feature, curated_dir, gmaps)\n",
    "\n",
    "hospital_type = \"hospital\"\n",
    "hospital_feature = \"hospital\"\n",
    "hospital_labels = [\"hospital complex\"]\n",
    "\n",
    "hospital_sf = feat_sf(foi_sf, hospital_feature, hospital_type, hospital_labels)\n",
    "hospital_haversine_df = rental_haversine_closest(cleaned_rental_df, hospital_sf, hospital_feature)\n",
    "hospital_rental_df = route_dist_and_save_csv(hospital_haversine_df, hospital_feature, curated_dir, gmaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding proximity of the rental property to their closest primary and secondary school**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_df = pd.read_csv(f\"{landing_dir}dv346-schoollocations2023.csv\", encoding = \"ISO-8859-1\")\n",
    "\n",
    "primary_school_type = [\"Primary\", \"Pri/Sec\"]\n",
    "primary_school_feautre = \"primary_school\"\n",
    "\n",
    "primary_school_df = feat_sf(school_df, primary_school_feautre, primary_school_type)\n",
    "primary_school_haversine_df = rental_haversine_closest(cleaned_rental_df, primary_school_df, primary_school_feautre)\n",
    "primary_school_rental_df = route_dist_and_save_csv(primary_school_haversine_df, primary_school_feautre, curated_dir, gmaps)\n",
    "\n",
    "secondary_school_type = [\"secondary\", \"Pri/Sec\"]\n",
    "secondary_school_feautre = \"secondary_school\"\n",
    "\n",
    "secondary_school_df = feat_sf(school_df, secondary_school_feautre, secondary_school_type)\n",
    "secondary_school_df = feat_sf(school_df, secondary_school_feautre, secondary_school_type)\n",
    "secondary_school_haversine_df = rental_haversine_closest(cleaned_rental_df, secondary_school_df, secondary_school_feautre)\n",
    "secondary_school_rental_df = route_dist_and_save_csv(secondary_school_haversine_df, secondary_school_feautre, curated_dir, gmaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining and saving all features and their distances into one single dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If restart notebook\n",
    "\"\"\"\n",
    "# Redownloading dfs just in case\n",
    "# cleaned_rental_df = pd.read_csv(f\"{raw_dir}rental_with_coordinates.csv\")\n",
    "# cbd_rental_df = pd.read_csv(f\"{curated_dir}rental_with_CBD.csv\")\n",
    "# train_station_rental_df = pd.read_csv(f\"{curated_dir}rental_with_train_station.csv\")\n",
    "# shopping_rental_df = pd.read_csv(f\"{curated_dir}rental_with_shopping.csv\")\n",
    "# parks_rental_df = pd.read_csv(f\"{curated_dir}rental_with_parks.csv\")\n",
    "# hospital_rental_df = pd.read_csv(f\"{curated_dir}rental_with_hospital.csv\")\n",
    "# primary_school_rental_df = pd.read_csv(f\"{curated_dir}rental_with_primary_school.csv\")\n",
    "# secondary_school_rental_df = pd.read_csv(f\"{curated_dir}rental_with_secondary_school.csv\")\n",
    "\n",
    "# columns_to_remove = cleaned_rental_df.columns\n",
    "\n",
    "# # Dropping common columns\n",
    "# train_station_rental_df = train_station_rental_df.drop(columns=columns_to_remove)\n",
    "# shopping_rental_df = shopping_rental_df.drop(columns=columns_to_remove)\n",
    "# parks_rental_df = parks_rental_df.drop(columns=columns_to_remove)\n",
    "# hospital_rental_df = hospital_rental_df.drop(columns=columns_to_remove)\n",
    "# primary_school_rental_df = primary_school_rental_df.drop(columns=columns_to_remove)\n",
    "# secondary_school_rental_df = secondary_school_rental_df.drop(columns=columns_to_remove)\n",
    "\n",
    "# Combining all columns\n",
    "# combined_df = pd.concat([cbd_rental_df, train_station_rental_df, shopping_rental_df, parks_rental_df, \n",
    "#                          hospital_rental_df, primary_school_rental_df, secondary_school_rental_df])\n",
    "\n",
    "# Save as csv\n",
    "# combined_df.to_csv(f\"{curated_dir}rental_with_all_features.csv\", index=False)\n",
    "\n",
    "\"\"\"\n",
    "If no need to restart notebook\n",
    "\"\"\"\n",
    "# Save as csv\n",
    "cleaned_rental_df.to_csv(f\"{curated_dir}rental_with_all_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
